{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b87cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Matheus\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Matheus\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5849625 0.        0.        0.        0.5849625 0.        0.\n",
      "  0.       ]\n",
      " [0.        0.        1.5849625 1.5849625 0.5849625 0.        0.\n",
      "  1.5849625]\n",
      " [0.        1.5849625 0.        0.        0.        0.        1.5849625\n",
      "  0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# Write a Python program to sum two sparse vectors. Each vector is a list of (index, float). Test the correctness of your algorithm.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Implement a TF-IDF vectorizer for text documents in Python.\n",
    "#\n",
    "# The vectorizer should transform a list of text documents into a floating-point\n",
    "# matrix of shape (D, V) where D is the number of documents in the training corpus\n",
    "# and V is the number of unique words in the training corpus. Each value T_ij\n",
    "# should correspond to the TF-IDF coefficient of the word j in document i.\n",
    "#\n",
    "# We'll use a simple version of TF-IDF without any smoothing:\n",
    "#\n",
    "# T_ij = TF * log2(IDF), where\n",
    "# TF = # occurrences of word j in document i\n",
    "# IDF = (# documents in the corpus) / (# of documents containing the word j)\n",
    "#\n",
    "# Example input (here you can see that D=3 and V=8):\n",
    "# \n",
    "# ['I like coffee',\n",
    "#  'They like tea and coffee',\n",
    "#  'Kids like milk']\n",
    "#\n",
    "# Example output:\n",
    "#\n",
    "#      (I)   (like) (coffee)  (They)  (tea)   (and)  (Kids)  (milk)\n",
    "# [[   1.58    0.00    0.58    0.00    0.00    0.00    0.00   0.00],\n",
    "#  [   0.00    0.00    0.58    1.58    1.58    1.58    0.00   0.00],\n",
    "#  [   0.00    0.00    0.00    0.00    0.00    0.00    1.58   1.58]]\n",
    "#\n",
    "# Test the correctness of your vectorizer.\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "inp = ['I like coffee',\n",
    "'They like tea and coffee',\n",
    "'Kids like milk']\n",
    "\n",
    "texts = [text.split() for text in inp]\n",
    "TFs = {}\n",
    "for idx, text in enumerate(texts):\n",
    "    TFs[idx] = Counter(text)\n",
    "\n",
    "docs_in_corpus = len(inp)\n",
    "\n",
    "all_text = ' '.join(inp)\n",
    "words = [word for word in all_text.split()]\n",
    "words = set(words)\n",
    "\n",
    "# print('words')\n",
    "# print(words)\n",
    "# print()\n",
    "\n",
    "docs_with_word = {} #defaultdict(lambda: 0)\n",
    "for word in words:\n",
    "    for text in texts:\n",
    "        if word in text:\n",
    "            if word not in docs_with_word:\n",
    "                docs_with_word[word] = 1\n",
    "            else:\n",
    "                docs_with_word[word] += 1\n",
    "\n",
    "# print('docs_with_word')\n",
    "# print(docs_with_word)\n",
    "# print()\n",
    "\n",
    "IDF = {}\n",
    "for word in words:\n",
    "    IDF[word] = docs_in_corpus / docs_with_word[word]\n",
    "\n",
    "sorted_words = sorted(list(words))\n",
    "\n",
    "num_cols = len(words)\n",
    "num_row = docs_in_corpus\n",
    "\n",
    "out_matrix = []\n",
    "for idx, text in enumerate(inp):\n",
    "    text = text.split()\n",
    "    out_vector = [0] * num_cols\n",
    "    for w_idx, word in enumerate(sorted_words):\n",
    "        T_ij = TFs[idx][word] * math.log2(IDF[word]) \n",
    "        out_vector[w_idx] = T_ij\n",
    "    out_matrix.append(out_vector)\n",
    "\n",
    "\n",
    "out_matrix = np.array(out_matrix)\n",
    "print(out_matrix)\n",
    "\n",
    "# right number of rows and columns\n",
    "assert out_matrix.shape[0] == docs_in_corpus, 'Wrong number of documents'\n",
    "assert out_matrix.shape[1] == num_cols, 'Wrong number of words'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
